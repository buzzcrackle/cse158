{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import urllib\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "import ast\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x90 in position 3182: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3167abb9ce42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrawdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_Category.json.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-3167abb9ce42>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrawdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_Category.json.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\jesse\\anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x90 in position 3182: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "rawdata = [eval(l) for l in gzip.open('train_Category.json.gz', 'rt', encoding=\"utf8\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rawdata\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramCount = defaultdict(int)\n",
    "bigramCount = defaultdict(int)\n",
    "totalUnigrams = 0\n",
    "totalBigrams = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    t = d['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    \n",
    "    if len(words) == 0:\n",
    "        continue\n",
    "    \n",
    "    totalUnigrams += 1\n",
    "    unigramCount[words[0]] += 1\n",
    "    \n",
    "    for i in range(len(words) - 1):\n",
    "        #w = stemmer.stem(w)\n",
    "        totalUnigrams += 1\n",
    "        unigramCount[words[i+1]] += 1\n",
    "        \n",
    "        bigram = words[i] + \" \" + words[i+1]\n",
    "        totalBigrams += 1\n",
    "        bigramCount[bigram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'totalUnigrams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-407ccf07b85d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtotalUnigrams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotalBigrams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'totalUnigrams' is not defined"
     ]
    }
   ],
   "source": [
    "totalUnigrams, totalBigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unigramCount' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e8ebc1ff0ef1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munigramCount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigramCount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'unigramCount' is not defined"
     ]
    }
   ],
   "source": [
    "len(unigramCount), len(bigramCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unigramCount' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d6576bb693aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munigramPairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munigramCount\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munigramCount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbigramPairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigramCount\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbigramCount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unigramCount' is not defined"
     ]
    }
   ],
   "source": [
    "unigramPairs = [(unigramCount[w], w) for w in unigramCount]\n",
    "bigramPairs = [(bigramCount[w], w) for w in bigramCount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unigramPairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0d911dc413e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munigramPairs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0munigramPairs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbigramPairs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbigramPairs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unigramPairs' is not defined"
     ]
    }
   ],
   "source": [
    "unigramPairs.sort()\n",
    "unigramPairs.reverse()\n",
    "bigramPairs.sort()\n",
    "bigramPairs.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unigramPairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4254d8a501bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munigrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munigramPairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbigrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbigramPairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unigramPairs' is not defined"
     ]
    }
   ],
   "source": [
    "unigrams = [w[1] for w in unigramPairs[:1000]]\n",
    "bigrams = [w[1] for w in bigramPairs[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramId = dict(zip(unigrams, range(len(unigrams))))\n",
    "unigramSet = set(unigrams)\n",
    "bigramId = dict(zip(bigrams, range(len(bigrams))))\n",
    "bigramSet = set(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2080628"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigramCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(77409, 'this game'),\n",
       " (71358, 'the game'),\n",
       " (56774, 'of the'),\n",
       " (34040, 'if you'),\n",
       " (33628, 'in the')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramPairs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigramFeature(datum):\n",
    "    feat = [0]*len(bigramSet)\n",
    "    t = datum['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    \n",
    "    if len(words) != 0:\n",
    "        for i in range(len(words) - 1):\n",
    "            bigram = words[i] + words[i+1]\n",
    "            if not (bigram in bigramSet): continue\n",
    "            feat[bigramId[bigram]] += 1\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [bigramFeature(d) for d in data]\n",
    "y = [math.log(d['hours'] + 1, 2) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = [eval(l) for l in gzip.open('test_Category.json.gz', 'rt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [bigramFeature(d) for d in data]\n",
    "y_test = [math.log(d['hours'] + 1, 2) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.304686532846429"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the top unigrams are more common than the top bigrams, I decided to simply combine the top 500 unigrams and top 500 bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "both = unigrams[:500] + bigrams[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bothId = dict(zip(both, range(len(both))))\n",
    "bothSet = set(both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bothFeature(datum):\n",
    "    feat = [0]*len(bothSet)\n",
    "    t = datum['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    \n",
    "    if len(words) != 0:\n",
    "        if words[0] in bothSet:\n",
    "            feat[bothId[words[0]]] += 1\n",
    "        \n",
    "        for i in range(len(words) - 1):\n",
    "            if words[i+1] in bothSet:\n",
    "                feat[bothId[words[i+1]]] += 1\n",
    "            \n",
    "            bigram = words[i] + words[i+1]\n",
    "            if bigram in bothSet:\n",
    "                feat[bothId[bigram]] += 1\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [bothFeature(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [bothFeature(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.800181543286911"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordsFromDoc(doc):\n",
    "    doc = doc.lower()\n",
    "    doc = [c for c in doc if not (c in punct)]\n",
    "    doc = ''.join(doc)\n",
    "    \n",
    "    return doc.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(term, doc):\n",
    "    words = wordsFromDoc(doc)\n",
    "    count = 0\n",
    "    \n",
    "    for w in words:\n",
    "        if w == term:\n",
    "            count += 1\n",
    "            \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IDF(term, Docs):\n",
    "    N = len(Docs)\n",
    "    count = 0\n",
    "    \n",
    "    for doc in Docs:\n",
    "        words = wordsFromDoc(doc)\n",
    "        if term in words:\n",
    "            count += 1\n",
    "            \n",
    "    return math.log(N / count, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Docs = [d['text'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idf scores\n",
      "destiny: 3.1159332503214863\n",
      "annoying: 1.7917122401967747\n",
      "likeable: 3.0786851929018573\n",
      "chapter: 2.2980621402742463\n",
      "interesting: 1.360969104250146\n"
     ]
    }
   ],
   "source": [
    "queries = {'destiny': None, 'annoying': None, 'likeable': None, 'chapter': None, 'interesting': None}\n",
    "\n",
    "print(\"idf scores\")\n",
    "for query in queries:\n",
    "    idf = IDF(query, Docs)\n",
    "    queries[query] = idf\n",
    "    print(f\"{query}: {idf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rID = 'r75487422'\n",
    "review = [d for d in data if d['reviewID'] == rID][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf scores\n",
      "destiny: 3.1159332503214863\n",
      "annoying: 3.5834244803935493\n",
      "likeable: 6.1573703858037145\n",
      "chapter: 6.894186420822739\n",
      "interesting: 2.721938208500292\n"
     ]
    }
   ],
   "source": [
    "print(\"tf-idf scores\")\n",
    "for query in queries:\n",
    "    tfidf = TF(query, review['text']) * queries[query]\n",
    "    print(f\"{query}: {tfidf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfCounts = defaultdict(int)\n",
    "\n",
    "for d in data:\n",
    "    t = d['text']\n",
    "    words = set(wordsFromDoc(t))\n",
    "    \n",
    "    for w in words:\n",
    "        if w in unigramSet:\n",
    "            idfCounts[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = defaultdict(float)\n",
    "\n",
    "N = len(data)\n",
    "for w in unigrams:\n",
    "    idfs[w] = math.log(N / idfCounts[w], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7917122401967747"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs['annoying']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [0]*len(unigramSet)\n",
    "    doc = datum['text']\n",
    "    words = wordsFromDoc(doc)\n",
    "    \n",
    "    wordCounts = defaultdict(int)\n",
    "    for w in words:\n",
    "        if w in unigramSet:\n",
    "            wordCounts[w] += 1\n",
    "            \n",
    "    for i in range(len(unigrams)):\n",
    "        w = unigrams[i]\n",
    "        feat[i] = wordCounts[w] * idfs[w]\n",
    "    \n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = feature(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5834244803935493"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat[unigrams.index('annoying')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [feature(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.71033668560965"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(A, B):\n",
    "    if len(A) != len(B):\n",
    "        return 0\n",
    "    \n",
    "    dot = 0\n",
    "    A_squared = 0\n",
    "    B_squared = 0\n",
    "    \n",
    "    for i in range(len(A) - 1): # Subtract 1 to ignore the 1 constant\n",
    "        dot += A[i] * B[i]\n",
    "        A_squared += A[i] ** 2\n",
    "        B_squared += B[i] ** 2\n",
    "    \n",
    "    A_mag = math.sqrt(A_squared)\n",
    "    B_mag = math.sqrt(B_squared)\n",
    "    denom = A_mag * B_mag\n",
    "    \n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    \n",
    "    return dot / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120185, 0.5575146920678062)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sim = -1\n",
    "index = -1\n",
    "\n",
    "review_vect = feature(review)\n",
    "review_index = data.index(review)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    if i == review_index:\n",
    "        continue\n",
    "    \n",
    "    sim = cosine(review_vect, X[i])\n",
    "    if sim > max_sim:\n",
    "        max_sim = sim\n",
    "        index = i\n",
    "\n",
    "index, max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r00449469'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[index]['reviewID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rawdata\n",
    "random.shuffle(data)\n",
    "data = data[:30000]\n",
    "\n",
    "y = [math.log(d['hours'] + 1, 2) for d in data]\n",
    "y_train = y[:10000]\n",
    "y_valid = y[10000:20000]\n",
    "y_test = y[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramCount = defaultdict(int)\n",
    "bigramCount = defaultdict(int)\n",
    "totalUnigrams = 0\n",
    "totalBigrams = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    t = d['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)]\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    \n",
    "    if len(words) == 0:\n",
    "        continue\n",
    "    \n",
    "    totalUnigrams += 1\n",
    "    unigramCount[words[0]] += 1\n",
    "    \n",
    "    for i in range(len(words) - 1):\n",
    "        #w = stemmer.stem(w)\n",
    "        totalUnigrams += 1\n",
    "        unigramCount[words[i+1]] += 1\n",
    "        \n",
    "        bigram = words[i] + \" \" + words[i+1]\n",
    "        totalBigrams += 1\n",
    "        bigramCount[bigram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramPairs = [(unigramCount[w], w) for w in unigramCount]\n",
    "bigramPairs = [(bigramCount[w], w) for w in bigramCount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramPairs.sort()\n",
    "unigramPairs.reverse()\n",
    "bigramPairs.sort()\n",
    "bigramPairs.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigramPairs[990:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = [w[1] for w in unigramPairs[:1000]]\n",
    "bigrams = [w[1] for w in bigramPairs[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramId = dict(zip(unigrams, range(len(unigrams))))\n",
    "unigramSet = set(unigrams)\n",
    "bigramId = dict(zip(bigrams, range(len(bigrams))))\n",
    "bigramSet = set(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramCount = defaultdict(int)\n",
    "bigramCount = defaultdict(int)\n",
    "totalUnigrams = 0\n",
    "totalBigrams = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    t = d['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c if (c not in punct) else f' {c} ' for c in t]\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    \n",
    "    if len(words) == 0:\n",
    "        continue\n",
    "    \n",
    "    totalUnigrams += 1\n",
    "    unigramCount[words[0]] += 1\n",
    "    \n",
    "    for i in range(len(words) - 1):\n",
    "        #w = stemmer.stem(w)\n",
    "        totalUnigrams += 1\n",
    "        unigramCount[words[i+1]] += 1\n",
    "        \n",
    "        bigram = words[i] + \" \" + words[i+1]\n",
    "        totalBigrams += 1\n",
    "        bigramCount[bigram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramPairs = [(unigramCount[w], w) for w in unigramCount]\n",
    "bigramPairs = [(bigramCount[w], w) for w in bigramCount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramPairs.sort()\n",
    "unigramPairs.reverse()\n",
    "bigramPairs.sort()\n",
    "bigramPairs.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramsPunc = [w[1] for w in unigramPairs[:1000]]\n",
    "bigramsPunc = [w[1] for w in bigramPairs[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramPuncId = dict(zip(unigramsPunc, range(len(unigramsPunc))))\n",
    "unigramPuncSet = set(unigramsPunc)\n",
    "bigramPuncId = dict(zip(bigramsPunc, range(len(bigramsPunc))))\n",
    "bigramPuncSet = set(bigramsPunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfUniCounts = defaultdict(int)\n",
    "idfBiCounts = defaultdict(int)\n",
    "\n",
    "for d in data:\n",
    "    t = d['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    \n",
    "    if len(words) != 0:\n",
    "        usedWords = set()\n",
    "        if words[0] in unigramSet:\n",
    "            idfUniCounts[words[0]] += 1\n",
    "        usedWords.add(words[0])\n",
    "        \n",
    "        for i in range(len(words) - 1):\n",
    "            if words[i+1] not in usedWords and words[i+1] in unigramSet:\n",
    "                idfUniCounts[words[i+1]] += 1\n",
    "                \n",
    "            bi = words[i] + \" \" + words[i+1]\n",
    "            if bi not in usedWords and bi in bigramSet:\n",
    "                idfBiCounts[bi] += 1\n",
    "            \n",
    "            usedWords.add(words[i+1])\n",
    "            usedWords.add(bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfUniCountsPunc = defaultdict(int)\n",
    "idfBiCountsPunc = defaultdict(int)\n",
    "\n",
    "for d in data:\n",
    "    t = d['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c if (c not in punct) else f' {c} ' for c in t]\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    \n",
    "    if len(words) != 0:\n",
    "        usedWords = set()\n",
    "        if words[0] in unigramPuncSet:\n",
    "            idfUniCountsPunc[words[0]] += 1\n",
    "        usedWords.add(words[0])\n",
    "        \n",
    "        for i in range(len(words) - 1):\n",
    "            if words[i+1] not in usedWords and words[i+1] in unigramPuncSet:\n",
    "                idfUniCountsPunc[words[i+1]] += 1\n",
    "                \n",
    "            bi = words[i] + \" \" + words[i+1]\n",
    "            if bi not in usedWords and bi in bigramPuncSet:\n",
    "                idfBiCountsPunc[bi] += 1\n",
    "\n",
    "            usedWords.add(words[i+1])\n",
    "            usedWords.add(bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs_uni = defaultdict(float)\n",
    "idfs_bi = defaultdict(float)\n",
    "\n",
    "N = len(data)\n",
    "for w in unigrams:\n",
    "    idfs_uni[w] = math.log(N / idfUniCounts[w], 10)\n",
    "\n",
    "for w in bigrams:\n",
    "    idfs_bi[w] = math.log(N / idfBiCounts[w], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs_uni_punc = defaultdict(float)\n",
    "idfs_bi_punc = defaultdict(float)\n",
    "\n",
    "N = len(data)\n",
    "for w in unigramsPunc:\n",
    "    idfs_uni_punc[w] = math.log(N / idfUniCountsPunc[w], 10)\n",
    "\n",
    "for w in bigramsPunc:\n",
    "    idfs_bi_punc[w] = math.log(N / idfBiCountsPunc[w], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurePuncOn(datum, unigram, tfidf):\n",
    "    feat = [0]*1000\n",
    "    t = datum['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c if (c not in punct) else f' {c} ' for c in t]\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "\n",
    "    wordCounts = defaultdict(int)\n",
    "    if unigram and not tfidf:\n",
    "        for w in words:\n",
    "            if w in unigramPuncSet:\n",
    "                feat[unigramPuncId[w]] += 1\n",
    "                \n",
    "    elif unigram and tfidf:\n",
    "        for w in words:\n",
    "            if w in unigramPuncSet:\n",
    "                wordCounts[w] += 1\n",
    "                \n",
    "        for w in unigramsPunc:\n",
    "            feat[unigramPuncId[w]] = wordCounts[w] * idfs_uni_punc[w]\n",
    "                \n",
    "    elif not unigram and not tfidf:\n",
    "        for i in range(len(words) - 1):\n",
    "            bi = words[i] + \" \" + words[i+1]\n",
    "            if bi in bigramPuncSet:\n",
    "                feat[bigramPuncId[bi]] += 1\n",
    "    else:\n",
    "        for i in range(len(words) - 1):\n",
    "            bi = words[i] + \" \" + words[i+1]\n",
    "            if bi in bigramPuncSet:\n",
    "                wordCounts[bi] += 1\n",
    "                \n",
    "        for w in bigramsPunc:\n",
    "            feat[bigramPuncId[w]] = wordCounts[w] * idfs_bi_punc[w]\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.867809634781638"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(featurePuncOn(data[0], False, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurePuncOff(datum, unigram, tfidf):\n",
    "    feat = [0]*1000\n",
    "    t = datum['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)]\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "\n",
    "    wordCounts = defaultdict(int)\n",
    "    if unigram and not tfidf:\n",
    "        for w in words:\n",
    "            if w in unigramSet:\n",
    "                feat[unigramId[w]] += 1\n",
    "                \n",
    "    elif unigram and tfidf:\n",
    "        for w in words:\n",
    "            if w in unigramSet:\n",
    "                wordCounts[w] += 1\n",
    "                \n",
    "        for w in unigrams:\n",
    "            feat[unigramId[w]] = wordCounts[w] * idfs_uni[w]\n",
    "                \n",
    "    elif not unigram and not tfidf:\n",
    "        for i in range(len(words) - 1):\n",
    "            bi = words[i] + \" \" + words[i+1]\n",
    "            if bi in bigramSet:\n",
    "                feat[bigramId[bi]] += 1\n",
    "    else:\n",
    "        for i in range(len(words) - 1):\n",
    "            bi = words[i] + \" \" + words[i+1]\n",
    "            if bi in bigramSet:\n",
    "                wordCounts[bi] += 1\n",
    "                \n",
    "        for w in bigrams:\n",
    "            feat[bigramId[w]] = wordCounts[w] * idfs_bi[w]\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labels = []\n",
    "X_train_list = []\n",
    "\n",
    "for uni in [True, False]:\n",
    "    for tf in [True, False]:\n",
    "        for pun in [True, False]:\n",
    "            label = \"\"\n",
    "            label += \"Uni-\" if uni else \"Bi-\"\n",
    "            label += \"Punct-\" if pun else \"NoPunct-\"\n",
    "            label += \"TFIDF\" if tf else \"Counts\"\n",
    "            X_labels.append(label)\n",
    "            new_X = []\n",
    "            if pun:\n",
    "                new_X = [featurePuncOn(d, uni, tf) for d in data]\n",
    "            else:\n",
    "                new_X = [featurePuncOff(d, uni, tf) for d in data]\n",
    "            X_train_list.append(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pairs = zip(X_labels, X_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uni-Punct-TFIDF: 0.01=>40.00220034024772, 0.1=>39.75634001071122, 1=>37.45138226067684, 10=>23.864667031901725, 100=>9.144604640058631, best MSE: 100=>7.993004576273152\n",
      "\n",
      "Uni-NoPunct-TFIDF: 0.01=>56.30370358005301, 0.1=>56.04669859257792, 1=>53.627711217070754, 10=>38.921326144545816, 100=>18.98169150239163, best MSE: 100=>5.181926305282538\n",
      "\n",
      "Uni-Punct-Counts: 0.01=>39.69555269292154, 0.1=>36.91842839454335, 1=>22.003462774652423, 10=>9.104519916115748, 100=>6.95698829943381, best MSE: 100=>5.097133869401024\n",
      "\n",
      "Uni-NoPunct-Counts: 0.01=>55.992599321853646, 0.1=>53.15628666454471, 1=>37.546856568855716, 10=>22.082967661051285, 100=>13.868514152056742, best MSE: 100=>5.034486406770679\n",
      "\n",
      "Bi-Punct-TFIDF: 0.01=>15.311978548710636, 0.1=>15.30549949467177, 1=>15.242991161960267, 10=>14.67940358654022, 100=>10.965460652252071, best MSE: 100=>5.4773194628332185\n",
      "\n",
      "Bi-NoPunct-TFIDF: 0.01=>328.0866031869517, 0.1=>325.07062164528656, 1=>297.0786702308165, 10=>143.99893144177335, 100=>13.094547003919091, best MSE: 100=>5.3521532776928\n",
      "\n",
      "Bi-Punct-Counts: 0.01=>15.305955589776223, 0.1=>15.245946391952433, 1=>14.688312729007935, 10=>11.014848442971598, 100=>5.8360914661233, best MSE: 100=>5.272686521060253\n",
      "\n",
      "Bi-NoPunct-Counts: 0.01=>324.62180978416006, 0.1=>293.2194822084745, 1=>132.31317562910138, 10=>11.76453163135753, 100=>5.221960088714792, best MSE: 100=>5.206983366473989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regs = [0.01, 0.1, 1, 10, 100]\n",
    "for X_name, X in X_pairs:\n",
    "    X_train = X[:10000]\n",
    "    X_valid = X[10000:20000]\n",
    "    X_test = X[20000:]\n",
    "    \n",
    "    MSEs = []\n",
    "    testMSEs = []\n",
    "    for c in regs:\n",
    "        model = linear_model.Ridge(c, fit_intercept=False)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_valid)\n",
    "        MSEs.append(mean_squared_error(y_valid, y_pred))\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        testMSEs.append(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "    bestIndex = MSEs.index(min(MSEs))\n",
    "    bestC = regs[bestIndex]\n",
    "    testMSE = testMSEs[bestIndex]\n",
    "    \n",
    "    result = X_name + \": \"\n",
    "    for i in range(len(regs)):\n",
    "        result += f\"{regs[i]}=>{MSEs[i]}, \"\n",
    "    \n",
    "    result += f\"best MSE: {bestC}=>{testMSE}\\n\"\n",
    "    \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the \"best MSE\" refers to the test MSE of the best model running on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
