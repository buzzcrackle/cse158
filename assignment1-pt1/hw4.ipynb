{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import urllib\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "import ast\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = [eval(l) for l in gzip.open('train_Category.json.gz', 'rt', encoding=\"utf8\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userID': 'u74382925',\n",
       " 'genre': 'Adventure',\n",
       " 'early_access': False,\n",
       " 'reviewID': 'r75487422',\n",
       " 'hours': 4.1,\n",
       " 'text': 'Short Review:\\nA good starting chapter for this series, despite the main character being annoying (for now) and a short length. The story is good and actually gets more interesting. Worth the try.\\nLong Review:\\nBlackwell Legacy is the first on the series of (supposedly) 5 games that talks about the main protagonist, Rosangela Blackwell, as being a so called Medium, and in this first chapter we get to know how her story will start and how she will meet her adventure companion Joey...and really, that\\'s really all for for now and that\\'s not a bad thing, because in a way this game wants to show how hard her new job is, and that she cannot escape her destiny as a medium.\\nMy biggest complain for this chapter, except the short length, it\\'s the main protagonist being a \"bit\" too annoying to be likeable, and most of her dialogues will always be about complaining or just be annoyed. Understandable, sure, but lighten\\' up will ya!?\\nHowever, considering that in the next installments she will be much more likeable and kind of interesting, I\\'d say give it a shot and see if you like it: if you hate this first game, you might like the next, or can always stop here.\\nI recommend it.',\n",
       " 'genreID': 3,\n",
       " 'date': '2014-02-07'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = rawdata\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramCount = defaultdict(int)\n",
    "bigramCount = defaultdict(int)\n",
    "totalUnigrams = 0\n",
    "totalBigrams = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    t = d['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    \n",
    "    if len(words) == 0:\n",
    "        continue\n",
    "    \n",
    "    totalUnigrams += 1\n",
    "    unigramCount[words[0]] += 1\n",
    "    \n",
    "    for i in range(len(words) - 1):\n",
    "        #w = stemmer.stem(w)\n",
    "        totalUnigrams += 1\n",
    "        unigramCount[words[i+1]] += 1\n",
    "        \n",
    "        bigram = words[i] + \" \" + words[i+1]\n",
    "        totalBigrams += 1\n",
    "        bigramCount[bigram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12161378, 11987793)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalUnigrams, totalBigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160503, 2080628)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unigramCount), len(bigramCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramPairs = [(unigramCount[w], w) for w in unigramCount]\n",
    "bigramPairs = [(bigramCount[w], w) for w in bigramCount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramPairs.sort()\n",
    "unigramPairs.reverse()\n",
    "bigramPairs.sort()\n",
    "bigramPairs.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = [w[1] for w in unigramPairs[:1000]]\n",
    "bigrams = [w[1] for w in bigramPairs[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramId = dict(zip(unigrams, range(len(unigrams))))\n",
    "unigramSet = set(unigrams)\n",
    "bigramId = dict(zip(bigrams, range(len(bigrams))))\n",
    "bigramSet = set(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2080628"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigramCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(77409, 'this game'),\n",
       " (71358, 'the game'),\n",
       " (56774, 'of the'),\n",
       " (34040, 'if you'),\n",
       " (33628, 'in the')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramPairs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigramFeature(datum):\n",
    "    feat = [0]*len(bigramSet)\n",
    "    t = datum['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    \n",
    "    if len(words) != 0:\n",
    "        for i in range(len(words) - 1):\n",
    "            bigram = words[i] + words[i+1]\n",
    "            if not (bigram in bigramSet): continue\n",
    "            feat[bigramId[bigram]] += 1\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [bigramFeature(d) for d in data]\n",
    "y = [math.log(d['hours'] + 1, 2) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = [eval(l) for l in gzip.open('test_Category.json.gz', 'rt', encoding=\"utf8\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [bigramFeature(d) for d in data]\n",
    "y_test = [math.log(d['hours'] + 1, 2) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.304686532846429"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the top unigrams are more common than the top bigrams, I decided to simply combine the top 500 unigrams and top 500 bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "both = unigrams[:500] + bigrams[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bothId = dict(zip(both, range(len(both))))\n",
    "bothSet = set(both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bothFeature(datum):\n",
    "    feat = [0]*len(bothSet)\n",
    "    t = datum['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    \n",
    "    if len(words) != 0:\n",
    "        if words[0] in bothSet:\n",
    "            feat[bothId[words[0]]] += 1\n",
    "        \n",
    "        for i in range(len(words) - 1):\n",
    "            if words[i+1] in bothSet:\n",
    "                feat[bothId[words[i+1]]] += 1\n",
    "            \n",
    "            bigram = words[i] + words[i+1]\n",
    "            if bigram in bothSet:\n",
    "                feat[bothId[bigram]] += 1\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [bothFeature(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [bothFeature(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.800181543286911"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordsFromDoc(doc):\n",
    "    doc = doc.lower()\n",
    "    doc = [c for c in doc if not (c in punct)]\n",
    "    doc = ''.join(doc)\n",
    "    \n",
    "    return doc.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(term, doc):\n",
    "    words = wordsFromDoc(doc)\n",
    "    count = 0\n",
    "    \n",
    "    for w in words:\n",
    "        if w == term:\n",
    "            count += 1\n",
    "            \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IDF(term, Docs):\n",
    "    N = len(Docs)\n",
    "    count = 0\n",
    "    \n",
    "    for doc in Docs:\n",
    "        words = wordsFromDoc(doc)\n",
    "        if term in words:\n",
    "            count += 1\n",
    "            \n",
    "    return math.log(N / count, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Docs = [d['text'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idf scores\n",
      "destiny: 3.1159332503214863\n",
      "annoying: 1.7917122401967747\n",
      "likeable: 3.0786851929018573\n",
      "chapter: 2.2980621402742463\n",
      "interesting: 1.360969104250146\n"
     ]
    }
   ],
   "source": [
    "queries = {'destiny': None, 'annoying': None, 'likeable': None, 'chapter': None, 'interesting': None}\n",
    "\n",
    "print(\"idf scores\")\n",
    "for query in queries:\n",
    "    idf = IDF(query, Docs)\n",
    "    queries[query] = idf\n",
    "    print(f\"{query}: {idf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rID = 'r75487422'\n",
    "review = [d for d in data if d['reviewID'] == rID][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf scores\n",
      "destiny: 3.1159332503214863\n",
      "annoying: 3.5834244803935493\n",
      "likeable: 6.1573703858037145\n",
      "chapter: 6.894186420822739\n",
      "interesting: 2.721938208500292\n"
     ]
    }
   ],
   "source": [
    "print(\"tf-idf scores\")\n",
    "for query in queries:\n",
    "    tfidf = TF(query, review['text']) * queries[query]\n",
    "    print(f\"{query}: {tfidf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfCounts = defaultdict(int)\n",
    "\n",
    "for d in data:\n",
    "    t = d['text']\n",
    "    words = set(wordsFromDoc(t))\n",
    "    \n",
    "    for w in words:\n",
    "        if w in unigramSet:\n",
    "            idfCounts[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = defaultdict(float)\n",
    "\n",
    "N = len(data)\n",
    "for w in unigrams:\n",
    "    idfs[w] = math.log(N / idfCounts[w], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7917122401967747"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs['annoying']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [0]*len(unigramSet)\n",
    "    doc = datum['text']\n",
    "    words = wordsFromDoc(doc)\n",
    "    \n",
    "    wordCounts = defaultdict(int)\n",
    "    for w in words:\n",
    "        if w in unigramSet:\n",
    "            wordCounts[w] += 1\n",
    "            \n",
    "    for i in range(len(unigrams)):\n",
    "        w = unigrams[i]\n",
    "        feat[i] = wordCounts[w] * idfs[w]\n",
    "    \n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = feature(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5834244803935493"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat[unigrams.index('annoying')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [feature(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(A, B):\n",
    "    if len(A) != len(B):\n",
    "        return 0\n",
    "    \n",
    "    dot = 0\n",
    "    A_squared = 0\n",
    "    B_squared = 0\n",
    "    \n",
    "    for i in range(len(A) - 1): # Subtract 1 to ignore the 1 constant\n",
    "        dot += A[i] * B[i]\n",
    "        A_squared += A[i] ** 2\n",
    "        B_squared += B[i] ** 2\n",
    "    \n",
    "    A_mag = math.sqrt(A_squared)\n",
    "    B_mag = math.sqrt(B_squared)\n",
    "    denom = A_mag * B_mag\n",
    "    \n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    \n",
    "    return dot / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sim = -1\n",
    "index = -1\n",
    "\n",
    "review_vect = feature(review)\n",
    "review_index = data.index(review)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    if i == review_index:\n",
    "        continue\n",
    "    \n",
    "    sim = cosine(review_vect, X[i])\n",
    "    if sim > max_sim:\n",
    "        max_sim = sim\n",
    "        index = i\n",
    "\n",
    "index, max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[index]['reviewID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rawdata\n",
    "random.shuffle(data)\n",
    "data = data[:30000]\n",
    "\n",
    "y = [math.log(d['hours'] + 1, 2) for d in data]\n",
    "y_train = y[:10000]\n",
    "y_valid = y[10000:20000]\n",
    "y_test = y[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramCount = defaultdict(int)\n",
    "bigramCount = defaultdict(int)\n",
    "totalUnigrams = 0\n",
    "totalBigrams = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    t = d['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)]\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    \n",
    "    if len(words) == 0:\n",
    "        continue\n",
    "    \n",
    "    totalUnigrams += 1\n",
    "    unigramCount[words[0]] += 1\n",
    "    \n",
    "    for i in range(len(words) - 1):\n",
    "        #w = stemmer.stem(w)\n",
    "        totalUnigrams += 1\n",
    "        unigramCount[words[i+1]] += 1\n",
    "        \n",
    "        bigram = words[i] + \" \" + words[i+1]\n",
    "        totalBigrams += 1\n",
    "        bigramCount[bigram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramPairs = [(unigramCount[w], w) for w in unigramCount]\n",
    "bigramPairs = [(bigramCount[w], w) for w in bigramCount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramPairs.sort()\n",
    "unigramPairs.reverse()\n",
    "bigramPairs.sort()\n",
    "bigramPairs.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigramPairs[990:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = [w[1] for w in unigramPairs[:1000]]\n",
    "bigrams = [w[1] for w in bigramPairs[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramId = dict(zip(unigrams, range(len(unigrams))))\n",
    "unigramSet = set(unigrams)\n",
    "bigramId = dict(zip(bigrams, range(len(bigrams))))\n",
    "bigramSet = set(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramCount = defaultdict(int)\n",
    "bigramCount = defaultdict(int)\n",
    "totalUnigrams = 0\n",
    "totalBigrams = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    t = d['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c if (c not in punct) else f' {c} ' for c in t]\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    \n",
    "    if len(words) == 0:\n",
    "        continue\n",
    "    \n",
    "    totalUnigrams += 1\n",
    "    unigramCount[words[0]] += 1\n",
    "    \n",
    "    for i in range(len(words) - 1):\n",
    "        #w = stemmer.stem(w)\n",
    "        totalUnigrams += 1\n",
    "        unigramCount[words[i+1]] += 1\n",
    "        \n",
    "        bigram = words[i] + \" \" + words[i+1]\n",
    "        totalBigrams += 1\n",
    "        bigramCount[bigram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramPairs = [(unigramCount[w], w) for w in unigramCount]\n",
    "bigramPairs = [(bigramCount[w], w) for w in bigramCount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramPairs.sort()\n",
    "unigramPairs.reverse()\n",
    "bigramPairs.sort()\n",
    "bigramPairs.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramsPunc = [w[1] for w in unigramPairs[:1000]]\n",
    "bigramsPunc = [w[1] for w in bigramPairs[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramPuncId = dict(zip(unigramsPunc, range(len(unigramsPunc))))\n",
    "unigramPuncSet = set(unigramsPunc)\n",
    "bigramPuncId = dict(zip(bigramsPunc, range(len(bigramsPunc))))\n",
    "bigramPuncSet = set(bigramsPunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfUniCounts = defaultdict(int)\n",
    "idfBiCounts = defaultdict(int)\n",
    "\n",
    "for d in data:\n",
    "    t = d['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    \n",
    "    if len(words) != 0:\n",
    "        usedWords = set()\n",
    "        if words[0] in unigramSet:\n",
    "            idfUniCounts[words[0]] += 1\n",
    "        usedWords.add(words[0])\n",
    "        \n",
    "        for i in range(len(words) - 1):\n",
    "            if words[i+1] not in usedWords and words[i+1] in unigramSet:\n",
    "                idfUniCounts[words[i+1]] += 1\n",
    "                \n",
    "            bi = words[i] + \" \" + words[i+1]\n",
    "            if bi not in usedWords and bi in bigramSet:\n",
    "                idfBiCounts[bi] += 1\n",
    "            \n",
    "            usedWords.add(words[i+1])\n",
    "            usedWords.add(bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfUniCountsPunc = defaultdict(int)\n",
    "idfBiCountsPunc = defaultdict(int)\n",
    "\n",
    "for d in data:\n",
    "    t = d['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c if (c not in punct) else f' {c} ' for c in t]\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    \n",
    "    if len(words) != 0:\n",
    "        usedWords = set()\n",
    "        if words[0] in unigramPuncSet:\n",
    "            idfUniCountsPunc[words[0]] += 1\n",
    "        usedWords.add(words[0])\n",
    "        \n",
    "        for i in range(len(words) - 1):\n",
    "            if words[i+1] not in usedWords and words[i+1] in unigramPuncSet:\n",
    "                idfUniCountsPunc[words[i+1]] += 1\n",
    "                \n",
    "            bi = words[i] + \" \" + words[i+1]\n",
    "            if bi not in usedWords and bi in bigramPuncSet:\n",
    "                idfBiCountsPunc[bi] += 1\n",
    "\n",
    "            usedWords.add(words[i+1])\n",
    "            usedWords.add(bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs_uni = defaultdict(float)\n",
    "idfs_bi = defaultdict(float)\n",
    "\n",
    "N = len(data)\n",
    "for w in unigrams:\n",
    "    idfs_uni[w] = math.log(N / idfUniCounts[w], 10)\n",
    "\n",
    "for w in bigrams:\n",
    "    idfs_bi[w] = math.log(N / idfBiCounts[w], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs_uni_punc = defaultdict(float)\n",
    "idfs_bi_punc = defaultdict(float)\n",
    "\n",
    "N = len(data)\n",
    "for w in unigramsPunc:\n",
    "    idfs_uni_punc[w] = math.log(N / idfUniCountsPunc[w], 10)\n",
    "\n",
    "for w in bigramsPunc:\n",
    "    idfs_bi_punc[w] = math.log(N / idfBiCountsPunc[w], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurePuncOn(datum, unigram, tfidf):\n",
    "    feat = [0]*1000\n",
    "    t = datum['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c if (c not in punct) else f' {c} ' for c in t]\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "\n",
    "    wordCounts = defaultdict(int)\n",
    "    if unigram and not tfidf:\n",
    "        for w in words:\n",
    "            if w in unigramPuncSet:\n",
    "                feat[unigramPuncId[w]] += 1\n",
    "                \n",
    "    elif unigram and tfidf:\n",
    "        for w in words:\n",
    "            if w in unigramPuncSet:\n",
    "                wordCounts[w] += 1\n",
    "                \n",
    "        for w in unigramsPunc:\n",
    "            feat[unigramPuncId[w]] = wordCounts[w] * idfs_uni_punc[w]\n",
    "                \n",
    "    elif not unigram and not tfidf:\n",
    "        for i in range(len(words) - 1):\n",
    "            bi = words[i] + \" \" + words[i+1]\n",
    "            if bi in bigramPuncSet:\n",
    "                feat[bigramPuncId[bi]] += 1\n",
    "    else:\n",
    "        for i in range(len(words) - 1):\n",
    "            bi = words[i] + \" \" + words[i+1]\n",
    "            if bi in bigramPuncSet:\n",
    "                wordCounts[bi] += 1\n",
    "                \n",
    "        for w in bigramsPunc:\n",
    "            feat[bigramPuncId[w]] = wordCounts[w] * idfs_bi_punc[w]\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(featurePuncOn(data[0], False, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurePuncOff(datum, unigram, tfidf):\n",
    "    feat = [0]*1000\n",
    "    t = datum['text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)]\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "\n",
    "    wordCounts = defaultdict(int)\n",
    "    if unigram and not tfidf:\n",
    "        for w in words:\n",
    "            if w in unigramSet:\n",
    "                feat[unigramId[w]] += 1\n",
    "                \n",
    "    elif unigram and tfidf:\n",
    "        for w in words:\n",
    "            if w in unigramSet:\n",
    "                wordCounts[w] += 1\n",
    "                \n",
    "        for w in unigrams:\n",
    "            feat[unigramId[w]] = wordCounts[w] * idfs_uni[w]\n",
    "                \n",
    "    elif not unigram and not tfidf:\n",
    "        for i in range(len(words) - 1):\n",
    "            bi = words[i] + \" \" + words[i+1]\n",
    "            if bi in bigramSet:\n",
    "                feat[bigramId[bi]] += 1\n",
    "    else:\n",
    "        for i in range(len(words) - 1):\n",
    "            bi = words[i] + \" \" + words[i+1]\n",
    "            if bi in bigramSet:\n",
    "                wordCounts[bi] += 1\n",
    "                \n",
    "        for w in bigrams:\n",
    "            feat[bigramId[w]] = wordCounts[w] * idfs_bi[w]\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labels = []\n",
    "X_train_list = []\n",
    "\n",
    "for uni in [True, False]:\n",
    "    for tf in [True, False]:\n",
    "        for pun in [True, False]:\n",
    "            label = \"\"\n",
    "            label += \"Uni-\" if uni else \"Bi-\"\n",
    "            label += \"Punct-\" if pun else \"NoPunct-\"\n",
    "            label += \"TFIDF\" if tf else \"Counts\"\n",
    "            X_labels.append(label)\n",
    "            new_X = []\n",
    "            if pun:\n",
    "                new_X = [featurePuncOn(d, uni, tf) for d in data]\n",
    "            else:\n",
    "                new_X = [featurePuncOff(d, uni, tf) for d in data]\n",
    "            X_train_list.append(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pairs = zip(X_labels, X_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = [0.01, 0.1, 1, 10, 100]\n",
    "for X_name, X in X_pairs:\n",
    "    X_train = X[:10000]\n",
    "    X_valid = X[10000:20000]\n",
    "    X_test = X[20000:]\n",
    "    \n",
    "    MSEs = []\n",
    "    testMSEs = []\n",
    "    for c in regs:\n",
    "        model = linear_model.Ridge(c, fit_intercept=False)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_valid)\n",
    "        MSEs.append(mean_squared_error(y_valid, y_pred))\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        testMSEs.append(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "    bestIndex = MSEs.index(min(MSEs))\n",
    "    bestC = regs[bestIndex]\n",
    "    testMSE = testMSEs[bestIndex]\n",
    "    \n",
    "    result = X_name + \": \"\n",
    "    for i in range(len(regs)):\n",
    "        result += f\"{regs[i]}=>{MSEs[i]}, \"\n",
    "    \n",
    "    result += f\"best MSE: {bestC}=>{testMSE}\\n\"\n",
    "    \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the \"best MSE\" refers to the test MSE of the best model running on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
